{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "import random\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import h5py\n",
    "import time\n",
    "import data_loader as loader\n",
    "from collections import defaultdict, OrderedDict\n",
    "import argparse\n",
    "import cPickle as pickle\n",
    "import time\n",
    "import json, os, ast, h5py\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(args,config):\n",
    "\ttr_split = 2.0/3                        # fixed. 62 training & validation, 31 test\n",
    "\tval_split = 0.1514                      # fixed. 52 training 10 validation\n",
    "\tuse_pretrained_word_embedding = True    # fixed. use glove 300d\n",
    "\tembedding_vecor_length = 300            # fixed. use glove 300d\n",
    "\t# 115                   # fixed for MOSI. The max length of a segment in MOSI dataset is 114\n",
    "\tmax_segment_len = config['seqlength']\n",
    "\tend_to_end = True                       # fixed\n",
    "\n",
    "\tword2ix = loader.load_word2ix()\n",
    "\tword_embedding = [loader.load_word_embedding()] if use_pretrained_word_embedding else None\n",
    "\ttrain, valid, test = loader.load_word_level_features(max_segment_len, tr_split)\n",
    "\n",
    "\tix2word = inv_map = {v: k for k, v in word2ix.iteritems()}\n",
    "\tprint len(word2ix)\n",
    "\tprint len(ix2word)\n",
    "\tprint word_embedding[0].shape\n",
    "\n",
    "\tfeature_str = ''\n",
    "\tif args.feature_selection:\n",
    "\t\twith open('/media/bighdd5/Paul/mosi/fs_mask.pkl') as f:\n",
    "\t\t\t[covarep_ix, facet_ix] = pickle.load(f)\n",
    "\t\tfacet_train = train['facet'][:,:,facet_ix]\n",
    "\t\tfacet_valid = valid['facet'][:,:,facet_ix]\n",
    "\t\tfacet_test = test['facet'][:,:,facet_ix]\n",
    "\t\tcovarep_train = train['covarep'][:,:,covarep_ix]\n",
    "\t\tcovarep_valid = valid['covarep'][:,:,covarep_ix]\n",
    "\t\tcovarep_test = test['covarep'][:,:,covarep_ix]\n",
    "\t\tfeature_str = '_t'+str(embedding_vecor_length) + '_c'+str(covarep_test.shape[2]) + '_f'+str(facet_test.shape[2])\n",
    "\telse:\n",
    "\t\tfacet_train = train['facet']\n",
    "\t\tfacet_valid = valid['facet']\n",
    "\t\tcovarep_train = train['covarep'][:,:,1:35]\n",
    "\t\tcovarep_valid = valid['covarep'][:,:,1:35]\n",
    "\t\tfacet_test = test['facet']\n",
    "\t\tcovarep_test = test['covarep'][:,:,1:35]\n",
    "\n",
    "\ttext_train = train['text']\n",
    "\ttext_valid = valid['text']\n",
    "\ttext_test = test['text']\n",
    "\ty_train = train['label']\n",
    "\ty_valid = valid['label']\n",
    "\ty_test = test['label']\n",
    "\n",
    "\tlengths_train = train['lengths']\n",
    "\tlengths_valid = valid['lengths']\n",
    "\tlengths_test = test['lengths']\n",
    "\n",
    "\t#f = h5py.File(\"out/mosi_lengths_test.hdf5\", \"w\")\n",
    "\t#f.create_dataset('d1',data=lengths_test)\n",
    "\t#f.close()\n",
    "\t#assert False\n",
    "\n",
    "\tfacet_train_max = np.max(np.max(np.abs(facet_train ), axis =0),axis=0)\n",
    "\tfacet_train_max[facet_train_max==0] = 1\n",
    "\t#covarep_train_max =  np.max(np.max(np.abs(covarep_train), axis =0),axis=0)\n",
    "\t#covarep_train_max[covarep_train_max==0] = 1\n",
    "\n",
    "\tfacet_train = facet_train / facet_train_max\n",
    "\tfacet_valid = facet_valid / facet_train_max\n",
    "\t#covarep_train = covarep_train / covarep_train_max\n",
    "\tfacet_test = facet_test / facet_train_max\n",
    "\t#covarep_test = covarep_test / covarep_train_max\n",
    "\n",
    "\ttext_input = Input(shape=(max_segment_len,), dtype='int32', name='text_input')\n",
    "\ttext_eb_layer = Embedding(word_embedding[0].shape[0], embedding_vecor_length, input_length=max_segment_len, weights=word_embedding, name = 'text_eb_layer', trainable=False)(text_input)\n",
    "\tmodel = Model(text_input, text_eb_layer)\n",
    "\ttext_train_emb = model.predict(text_train)\n",
    "\tprint text_train_emb.shape      # n x seq x 300\n",
    "\tprint covarep_train.shape       # n x seq x 5/34\n",
    "\tprint facet_train.shape         # n x seq x 20/43\n",
    "\tX_train = np.concatenate((text_train_emb, covarep_train, facet_train), axis=2)\n",
    "\n",
    "\ttext_valid_emb = model.predict(text_valid)\n",
    "\tprint text_valid_emb.shape      # n x seq x 300\n",
    "\tprint covarep_valid.shape       # n x seq x 5/34\n",
    "\tprint facet_valid.shape         # n x seq x 20/43\n",
    "\tX_valid = np.concatenate((text_valid_emb, covarep_valid, facet_valid), axis=2)\n",
    "\n",
    "\ttext_test_emb = model.predict(text_test)\n",
    "\tprint text_test_emb.shape      # n x seq x 300\n",
    "\tprint covarep_test.shape       # n x seq x 5/34\n",
    "\tprint facet_test.shape         # n x seq x 20/43\n",
    "\tX_test = np.concatenate((text_test_emb, covarep_test, facet_test), axis=2)\n",
    "\n",
    "\treturn X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "\n",
    "def load_saved_data():\n",
    "\th5f = h5py.File('data/X_train.h5','r')\n",
    "\tX_train = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\th5f = h5py.File('data/y_train.h5','r')\n",
    "\ty_train = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\th5f = h5py.File('data/X_valid.h5','r')\n",
    "\tX_valid = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\th5f = h5py.File('data/y_valid.h5','r')\n",
    "\ty_valid = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\th5f = h5py.File('data/X_test.h5','r')\n",
    "\tX_test = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\th5f = h5py.File('data/y_test.h5','r')\n",
    "\ty_test = h5f['data'][:]\n",
    "\th5f.close()\n",
    "\treturn X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EFLSTM(nn.Module):\n",
    "\tdef __init__(self, d, h, output_dim, dropout): #, n_layers, bidirectional, dropout):\n",
    "\t\tsuper(EFLSTM, self).__init__()\n",
    "\t\tself.h = h\n",
    "\t\tself.lstm = nn.LSTMCell(d, h)\n",
    "\t\tself.fc1 = nn.Linear(h, h)\n",
    "\t\tself.fc2 = nn.Linear(h, output_dim)\n",
    "\t\tself.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# x is t x n x d\n",
    "\t\tt = x.shape[0]\n",
    "\t\tn = x.shape[1]\n",
    "\t\tself.hx = torch.zeros(n, self.h)\n",
    "\t\tself.cx = torch.zeros(n, self.h)\n",
    "\t\tall_hs = []\n",
    "\t\tall_cs = []\n",
    "\t\tfor i in range(t):\n",
    "\t\t\tself.hx, self.cx = self.lstm(x[i], (self.hx, self.cx))\n",
    "\t\t\tall_hs.append(self.hx)\n",
    "\t\t\tall_cs.append(self.cx)\n",
    "\t\t# last hidden layer last_hs is n x h\n",
    "\t\tlast_hs = all_hs[-1]\n",
    "\t\toutput = F.relu(self.fc1(last_hs))\n",
    "\t\toutput = self.dropout(output)\n",
    "\t\toutput = self.fc2(output)\n",
    "\t\treturn output\n",
    "\n",
    "class MFN(nn.Module):\n",
    "\tdef __init__(self,config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig):\n",
    "\t\tsuper(MFN, self).__init__()\n",
    "\t\t[self.d_l,self.d_a,self.d_v] = config[\"input_dims\"]\n",
    "\t\t[self.dh_l,self.dh_a,self.dh_v] = config[\"h_dims\"]\n",
    "\t\ttotal_h_dim = self.dh_l+self.dh_a+self.dh_v\n",
    "\t\tself.mem_dim = config[\"memsize\"]\n",
    "\t\twindow_dim = config[\"windowsize\"]\n",
    "\t\toutput_dim = 1\n",
    "\t\tattInShape = total_h_dim*window_dim\n",
    "\t\tgammaInShape = attInShape+self.mem_dim\n",
    "\t\tfinal_out = total_h_dim+self.mem_dim\n",
    "\t\th_att1 = NN1Config[\"shapes\"]\n",
    "\t\th_att2 = NN2Config[\"shapes\"]\n",
    "\t\th_gamma1 = gamma1Config[\"shapes\"]\n",
    "\t\th_gamma2 = gamma2Config[\"shapes\"]\n",
    "\t\th_out = outConfig[\"shapes\"]\n",
    "\t\tatt1_dropout = NN1Config[\"drop\"]\n",
    "\t\tatt2_dropout = NN2Config[\"drop\"]\n",
    "\t\tgamma1_dropout = gamma1Config[\"drop\"]\n",
    "\t\tgamma2_dropout = gamma2Config[\"drop\"]\n",
    "\t\tout_dropout = outConfig[\"drop\"]\n",
    "\n",
    "\t\tself.lstm_l = nn.LSTMCell(self.d_l, self.dh_l)\n",
    "\t\tself.lstm_a = nn.LSTMCell(self.d_a, self.dh_a)\n",
    "\t\tself.lstm_v = nn.LSTMCell(self.d_v, self.dh_v)\n",
    "\n",
    "\t\tself.att1_fc1 = nn.Linear(attInShape, h_att1)\n",
    "\t\tself.att1_fc2 = nn.Linear(h_att1, attInShape)\n",
    "\t\tself.att1_dropout = nn.Dropout(att1_dropout)\n",
    "\n",
    "\t\tself.att2_fc1 = nn.Linear(attInShape, h_att2)\n",
    "\t\tself.att2_fc2 = nn.Linear(h_att2, self.mem_dim)\n",
    "\t\tself.att2_dropout = nn.Dropout(att2_dropout)\n",
    "\n",
    "\t\tself.gamma1_fc1 = nn.Linear(gammaInShape, h_gamma1)\n",
    "\t\tself.gamma1_fc2 = nn.Linear(h_gamma1, self.mem_dim)\n",
    "\t\tself.gamma1_dropout = nn.Dropout(gamma1_dropout)\n",
    "\n",
    "\t\tself.gamma2_fc1 = nn.Linear(gammaInShape, h_gamma2)\n",
    "\t\tself.gamma2_fc2 = nn.Linear(h_gamma2, self.mem_dim)\n",
    "\t\tself.gamma2_dropout = nn.Dropout(gamma2_dropout)\n",
    "\n",
    "\t\tself.out_fc1 = nn.Linear(final_out, h_out)\n",
    "\t\tself.out_fc2 = nn.Linear(h_out, output_dim)\n",
    "\t\tself.out_dropout = nn.Dropout(out_dropout)\n",
    "\n",
    "\tdef forward(self,x):\n",
    "\t\tx_l = x[:,:,:self.d_l]\n",
    "\t\tx_a = x[:,:,self.d_l:self.d_l+self.d_a]\n",
    "\t\tx_v = x[:,:,self.d_l+self.d_a:]\n",
    "\t\t# x is t x n x d\n",
    "\t\tn = x.shape[1]\n",
    "\t\tt = x.shape[0]\n",
    "\t\tself.h_l = torch.zeros(n, self.dh_l)\n",
    "\t\tself.h_a = torch.zeros(n, self.dh_a)\n",
    "\t\tself.h_v = torch.zeros(n, self.dh_v)\n",
    "\t\tself.c_l = torch.zeros(n, self.dh_l)\n",
    "\t\tself.c_a = torch.zeros(n, self.dh_a)\n",
    "\t\tself.c_v = torch.zeros(n, self.dh_v)\n",
    "\t\tself.mem = torch.zeros(n, self.mem_dim)\n",
    "\t\tall_h_ls = []\n",
    "\t\tall_h_as = []\n",
    "\t\tall_h_vs = []\n",
    "\t\tall_c_ls = []\n",
    "\t\tall_c_as = []\n",
    "\t\tall_c_vs = []\n",
    "\t\tall_mems = []\n",
    "\t\tfor i in range(t):\n",
    "\t\t\t# prev time step\n",
    "\t\t\tprev_c_l = self.c_l\n",
    "\t\t\tprev_c_a = self.c_a\n",
    "\t\t\tprev_c_v = self.c_v\n",
    "\t\t\t# curr time step\n",
    "\t\t\tnew_h_l, new_c_l = self.lstm_l(x_l[i], (self.h_l, self.c_l))\n",
    "\t\t\tnew_h_a, new_c_a = self.lstm_a(x_a[i], (self.h_a, self.c_a))\n",
    "\t\t\tnew_h_v, new_c_v = self.lstm_v(x_v[i], (self.h_v, self.c_v))\n",
    "\t\t\t# concatenate\n",
    "\t\t\tprev_cs = torch.cat([prev_c_l,prev_c_a,prev_c_v], dim=1)\n",
    "\t\t\tnew_cs = torch.cat([new_c_l,new_c_a,new_c_v], dim=1)\n",
    "\t\t\tcStar = torch.cat([prev_cs,new_cs], dim=1)\n",
    "\t\t\tattention = F.softmax(self.att1_fc2(self.att1_dropout(F.relu(self.att1_fc1(cStar)))),dim=1)\n",
    "\t\t\tattended = attention*cStar\n",
    "\t\t\tcHat = F.tanh(self.att2_fc2(self.att2_dropout(F.relu(self.att2_fc1(attended)))))\n",
    "\t\t\tboth = torch.cat([attended,self.mem], dim=1)\n",
    "\t\t\tgamma1 = F.sigmoid(self.gamma1_fc2(self.gamma1_dropout(F.relu(self.gamma1_fc1(both)))))\n",
    "\t\t\tgamma2 = F.sigmoid(self.gamma2_fc2(self.gamma2_dropout(F.relu(self.gamma2_fc1(both)))))\n",
    "\t\t\tself.mem = gamma1*self.mem + gamma2*cHat\n",
    "\t\t\tall_mems.append(self.mem)\n",
    "\t\t\t# update\n",
    "\t\t\tself.h_l, self.c_l = new_h_l, new_c_l\n",
    "\t\t\tself.h_a, self.c_a = new_h_a, new_c_a\n",
    "\t\t\tself.h_v, self.c_v = new_h_v, new_c_v\n",
    "\t\t\tall_h_ls.append(self.h_l)\n",
    "\t\t\tall_h_as.append(self.h_a)\n",
    "\t\t\tall_h_vs.append(self.h_v)\n",
    "\t\t\tall_c_ls.append(self.c_l)\n",
    "\t\t\tall_c_as.append(self.c_a)\n",
    "\t\t\tall_c_vs.append(self.c_v)\n",
    "\n",
    "\t\t# last hidden layer last_hs is n x h\n",
    "\t\tlast_h_l = all_h_ls[-1]\n",
    "\t\tlast_h_a = all_h_as[-1]\n",
    "\t\tlast_h_v = all_h_vs[-1]\n",
    "\t\tlast_mem = all_mems[-1]\n",
    "\t\tlast_hs = torch.cat([last_h_l,last_h_a,last_h_v,last_mem], dim=1)\n",
    "\t\toutput = self.out_fc2(self.out_dropout(F.relu(self.out_fc1(last_hs))))\n",
    "\t\treturn output\n",
    "\n",
    "def train_ef(X_train, y_train, X_valid, y_valid, X_test, y_test, config):\n",
    "\tp = np.random.permutation(X_train.shape[0])\n",
    "\tX_train = X_train[p]\n",
    "\ty_train = y_train[p]\n",
    "\n",
    "\tX_train = X_train.swapaxes(0,1)\n",
    "\tX_valid = X_valid.swapaxes(0,1)\n",
    "\tX_test = X_test.swapaxes(0,1)\n",
    "\n",
    "\td = X_train.shape[2]\n",
    "\th = config[\"h\"]\n",
    "\tt = X_train.shape[0]\n",
    "\toutput_dim = 1\n",
    "\tdropout = config[\"drop\"]\n",
    "\n",
    "\tmodel = EFLSTM(d,h,output_dim,dropout)\n",
    "\n",
    "\toptimizer = optim.Adam(model.parameters(),lr=config[\"lr\"])\n",
    "\t#optimizer = optim.SGD(model.parameters(),lr=config[\"lr\"],momentum=config[\"momentum\"])\n",
    "\n",
    "\t# optimizer = optim.SGD([\n",
    "\t#                 {'params':model.lstm_l.parameters(), 'lr':config[\"lr\"]},\n",
    "\t#                 {'params':model.classifier.parameters(), 'lr':config[\"lr\"]}\n",
    "\t#             ], momentum=0.9)\n",
    "\n",
    "\tcriterion = nn.L1Loss()\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\tmodel = model.to(device)\n",
    "\tcriterion = criterion.to(device)\n",
    "\tscheduler = ReduceLROnPlateau(optimizer,mode='min',patience=100,factor=0.5,verbose=True)\n",
    "\n",
    "\tdef train(model, batchsize, X_train, y_train, optimizer, criterion):\n",
    "\t\tepoch_loss = 0\n",
    "\t\tmodel.train()\n",
    "\t\ttotal_n = X_train.shape[1]\n",
    "\t\tnum_batches = total_n / batchsize\n",
    "\t\tfor batch in xrange(num_batches):\n",
    "\t\t\tstart = batch*batchsize\n",
    "\t\t\tend = (batch+1)*batchsize\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tbatch_X = torch.Tensor(X_train[:,start:end])\n",
    "\t\t\tbatch_y = torch.Tensor(y_train[start:end])\n",
    "\t\t\tpredictions = model.forward(batch_X).squeeze(1)\n",
    "\t\t\tloss = criterion(predictions, batch_y)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\t\treturn epoch_loss / num_batches\n",
    "\n",
    "\tdef evaluate(model, X_valid, y_valid, criterion):\n",
    "\t\tepoch_loss = 0\n",
    "\t\tmodel.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tbatch_X = torch.Tensor(X_valid)\n",
    "\t\t\tbatch_y = torch.Tensor(y_valid)\n",
    "\t\t\tpredictions = model.forward(batch_X).squeeze(1)\n",
    "\t\t\tepoch_loss = criterion(predictions, batch_y).item()\n",
    "\t\treturn epoch_loss\n",
    "\n",
    "\tdef predict(model, X_test):\n",
    "\t\tepoch_loss = 0\n",
    "\t\tmodel.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tbatch_X = torch.Tensor(X_test)\n",
    "\t\t\tpredictions = model.forward(batch_X).squeeze(1)\n",
    "\t\t\tpredictions = predictions.cpu().data.numpy()\n",
    "\t\treturn predictions\n",
    "\n",
    "\t# timing\n",
    "\tstart_time = time.time()\n",
    "\tpredictions = predict(model, X_test)\n",
    "\tprint predictions.shape\n",
    "\tprint predictions\n",
    "\tend_time = time.time()\n",
    "\tprint end_time-start_time\n",
    "\tassert False\n",
    "\n",
    "\tbest_valid = 999999.0\n",
    "\trand = random.randint(0,100000)\n",
    "\tfor epoch in range(config[\"num_epochs\"]):\n",
    "\t\ttrain_loss = train(model, config[\"batchsize\"], X_train, y_train, optimizer, criterion)\n",
    "\t\tvalid_loss = evaluate(model, X_valid, y_valid, criterion)\n",
    "\t\tscheduler.step(valid_loss)\n",
    "\t\tif valid_loss <= best_valid:\n",
    "\t\t\t# save model\n",
    "\t\t\tbest_valid = valid_loss\n",
    "\t\t\tprint epoch, train_loss, valid_loss, 'saving model'\n",
    "\t\t\ttorch.save(model, 'res_mfn2/mfn_%d.pt' %rand)\n",
    "\t\telse:\n",
    "\t\t\tprint epoch, train_loss, valid_loss\n",
    "\n",
    "\tmodel = torch.load('res_mfn2/mfn_%d.pt' %rand)\n",
    "\n",
    "\tpredictions = predict(model, X_test)\n",
    "\tmae = np.mean(np.absolute(predictions-y_test))\n",
    "\tprint \"mae: \", mae\n",
    "\tcorr = np.corrcoef(predictions,y_test)[0][1]\n",
    "\tprint \"corr: \", corr\n",
    "\tmult = round(sum(np.round(predictions)==np.round(y_test))/float(len(y_test)),5)\n",
    "\tprint \"mult_acc: \", mult\n",
    "\tf_score = round(f1_score(np.round(predictions),np.round(y_test),average='weighted'),5)\n",
    "\tprint \"mult f_score: \", f_score\n",
    "\ttrue_label = (y_test >= 0)\n",
    "\tpredicted_label = (predictions >= 0)\n",
    "\tprint \"Confusion Matrix :\"\n",
    "\tprint confusion_matrix(true_label, predicted_label)\n",
    "\tprint \"Classification Report :\"\n",
    "\tprint classification_report(true_label, predicted_label, digits=5)\n",
    "\tprint \"Accuracy \", accuracy_score(true_label, predicted_label)\n",
    "\tsys.stdout.flush()\n",
    "\n",
    "def train_mfn(X_train, y_train, X_valid, y_valid, X_test, y_test, configs):\n",
    "\tp = np.random.permutation(X_train.shape[0])\n",
    "\tX_train = X_train[p]\n",
    "\ty_train = y_train[p]\n",
    "\n",
    "\tX_train = X_train.swapaxes(0,1)\n",
    "\tX_valid = X_valid.swapaxes(0,1)\n",
    "\tX_test = X_test.swapaxes(0,1)\n",
    "\n",
    "\td = X_train.shape[2]\n",
    "\th = 128\n",
    "\tt = X_train.shape[0]\n",
    "\toutput_dim = 1\n",
    "\tdropout = 0.5\n",
    "\n",
    "\t[config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig] = configs\n",
    "\n",
    "\t#model = EFLSTM(d,h,output_dim,dropout)\n",
    "\tmodel = MFN(config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig)\n",
    "\n",
    "\toptimizer = optim.Adam(model.parameters(),lr=config[\"lr\"])\n",
    "\t#optimizer = optim.SGD(model.parameters(),lr=config[\"lr\"],momentum=config[\"momentum\"])\n",
    "\n",
    "\t# optimizer = optim.SGD([\n",
    "\t#                 {'params':model.lstm_l.parameters(), 'lr':config[\"lr\"]},\n",
    "\t#                 {'params':model.classifier.parameters(), 'lr':config[\"lr\"]}\n",
    "\t#             ], momentum=0.9)\n",
    "\n",
    "\tcriterion = nn.L1Loss()\n",
    "\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\tmodel = model.to(device)\n",
    "\tcriterion = criterion.to(device)\n",
    "\tscheduler = ReduceLROnPlateau(optimizer,mode='min',patience=100,factor=0.5,verbose=True)\n",
    "\n",
    "\tdef train(model, batchsize, X_train, y_train, optimizer, criterion):\n",
    "\t\tepoch_loss = 0\n",
    "\t\tmodel.train()\n",
    "\t\ttotal_n = X_train.shape[1]\n",
    "\t\tnum_batches = total_n / batchsize\n",
    "\t\tfor batch in xrange(num_batches):\n",
    "\t\t\tstart = batch*batchsize\n",
    "\t\t\tend = (batch+1)*batchsize\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tbatch_X = torch.Tensor(X_train[:,start:end])\n",
    "\t\t\tbatch_y = torch.Tensor(y_train[start:end])\n",
    "\t\t\tpredictions = model.forward(batch_X).squeeze(1)\n",
    "\t\t\tloss = criterion(predictions, batch_y)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\t\treturn epoch_loss / num_batches\n",
    "\n",
    "\tdef evaluate(model, X_valid, y_valid, criterion):\n",
    "\t\tepoch_loss = 0\n",
    "\t\tmodel.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tbatch_X = torch.Tensor(X_valid)\n",
    "\t\t\tbatch_y = torch.Tensor(y_valid)\n",
    "\t\t\tpredictions = model.forward(batch_X).squeeze(1)\n",
    "\t\t\tepoch_loss = criterion(predictions, batch_y).item()\n",
    "\t\treturn epoch_loss\n",
    "\n",
    "\tdef predict(model, X_test):\n",
    "\t\tepoch_loss = 0\n",
    "\t\tmodel.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tbatch_X = torch.Tensor(X_test)\n",
    "\t\t\tpredictions = model.forward(batch_X).squeeze(1)\n",
    "\t\t\tpredictions = predictions.cpu().data.numpy()\n",
    "\t\treturn predictions\n",
    "\n",
    "\tbest_valid = 999999.0\n",
    "\trand = random.randint(0,100000)\n",
    "\tfor epoch in range(config[\"num_epochs\"]):\n",
    "\t\ttrain_loss = train(model, config[\"batchsize\"], X_train, y_train, optimizer, criterion)\n",
    "\t\tvalid_loss = evaluate(model, X_valid, y_valid, criterion)\n",
    "\t\tscheduler.step(valid_loss)\n",
    "\t\tif valid_loss <= best_valid:\n",
    "\t\t\t# save model\n",
    "\t\t\tbest_valid = valid_loss\n",
    "\t\t\tprint epoch, train_loss, valid_loss, 'saving model'\n",
    "\t\t\ttorch.save(model, 'temp_models/mfn_%d.pt' %rand)\n",
    "\t\telse:\n",
    "\t\t\tprint epoch, train_loss, valid_loss\n",
    "\n",
    "\tprint 'model number is:', rand\n",
    "\tmodel = torch.load('temp_models/mfn_%d.pt' %rand)\n",
    "\n",
    "\tpredictions = predict(model, X_test)\n",
    "\tmae = np.mean(np.absolute(predictions-y_test))\n",
    "\tprint \"mae: \", mae\n",
    "\tcorr = np.corrcoef(predictions,y_test)[0][1]\n",
    "\tprint \"corr: \", corr\n",
    "\tmult = round(sum(np.round(predictions)==np.round(y_test))/float(len(y_test)),5)\n",
    "\tprint \"mult_acc: \", mult\n",
    "\tf_score = round(f1_score(np.round(predictions),np.round(y_test),average='weighted'),5)\n",
    "\tprint \"mult f_score: \", f_score\n",
    "\ttrue_label = (y_test >= 0)\n",
    "\tpredicted_label = (predictions >= 0)\n",
    "\tprint \"Confusion Matrix :\"\n",
    "\tprint confusion_matrix(true_label, predicted_label)\n",
    "\tprint \"Classification Report :\"\n",
    "\tprint classification_report(true_label, predicted_label, digits=5)\n",
    "\tprint \"Accuracy \", accuracy_score(true_label, predicted_label)\n",
    "\tsys.stdout.flush()\n",
    "\n",
    "def test(X_test, y_test, metric):\n",
    "\tX_test = X_test.swapaxes(0,1)\n",
    "\tdef predict(model, X_test):\n",
    "\t\tepoch_loss = 0\n",
    "\t\tmodel.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tbatch_X = torch.Tensor(X_test)\n",
    "\t\t\tpredictions = model.forward(batch_X).squeeze(1)\n",
    "\t\t\tpredictions = predictions.cpu().data.numpy()\n",
    "\t\treturn predictions\n",
    "\n",
    "\tif torch.cuda.is_available():\n",
    "\t    map_location=lambda storage, loc: storage\n",
    "\telse:\n",
    "\t    map_location='cpu'\n",
    "\n",
    "\tif metric == 'mae':\n",
    "\t\tmodel = torch.load('best/mfn_mae.pt', map_location=map_location)\n",
    "\tif metric == 'acc':\n",
    "\t\tmodel = torch.load('best/mfn_acc.pt', map_location=map_location)\n",
    "\tmodel = model.cpu()\n",
    "\n",
    "\tpredictions = predict(model, X_test)\n",
    "\tprint predictions.shape\n",
    "\tprint y_test.shape\n",
    "\tmae = np.mean(np.absolute(predictions-y_test))\n",
    "\tprint \"mae: \", mae\n",
    "\tcorr = np.corrcoef(predictions,y_test)[0][1]\n",
    "\tprint \"corr: \", corr\n",
    "\tmult = round(sum(np.round(predictions)==np.round(y_test))/float(len(y_test)),5)\n",
    "\tprint \"mult_acc: \", mult\n",
    "\tf_score = round(f1_score(np.round(predictions),np.round(y_test),average='weighted'),5)\n",
    "\tprint \"mult f_score: \", f_score\n",
    "\ttrue_label = (y_test >= 0)\n",
    "\tpredicted_label = (predictions >= 0)\n",
    "\tprint \"Confusion Matrix :\"\n",
    "\tprint confusion_matrix(true_label, predicted_label)\n",
    "\tprint \"Classification Report :\"\n",
    "\tprint classification_report(true_label, predicted_label, digits=5)\n",
    "\tprint \"Accuracy \", accuracy_score(true_label, predicted_label)\n",
    "\tsys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='')\n",
    "parser.add_argument('--config', default='configs/mosi.json', type=str)\n",
    "parser.add_argument('--type', default='mgddm', type=str)\t# d, gd, m1, m3\n",
    "parser.add_argument('--fusion', default='mfn', type=str)\t# ef, tf, mv, marn, mfn\n",
    "parser.add_argument('-s', '--feature_selection', default=1, type=int, choices=[0,1], help='whether to use feature_selection')\n",
    "\n",
    "args = parser.parse_args(\"--config configs/mosi.json\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, X_test, y_test = load_saved_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'acc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tX_test = X_test.swapaxes(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 686, 325)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 20, 325)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " \tdef predict(model, X_test):\n",
    "\t\tepoch_loss = 0\n",
    "\t\tmodel.eval()\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tbatch_X = torch.Tensor(X_test)\n",
    "\t\t\tpredictions = model.forward(batch_X).squeeze(1)\n",
    "\t\t\tpredictions = predictions.cpu().data.numpy()\n",
    "\t\treturn predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tif torch.cuda.is_available():\n",
    "\t    map_location=lambda storage, loc: storage\n",
    "\telse:\n",
    "\t    map_location='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenlin/miniconda3/envs/py2/lib/python2.7/site-packages/torch/serialization.py:559: UserWarning: Couldn't retrieve source code for container of type MFN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + container_type.__name__ + \". It won't be checked \"\n",
      "/home/chenlin/miniconda3/envs/py2/lib/python2.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.rnn.LSTMCell' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/chenlin/miniconda3/envs/py2/lib/python2.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/chenlin/miniconda3/envs/py2/lib/python2.7/site-packages/torch/serialization.py:593: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "\tif metric == 'mae':\n",
    "\t\tmodel = torch.load('best/mfn_mae.pt', map_location=map_location)\n",
    "\tif metric == 'acc':\n",
    "\t\tmodel = torch.load('best/mfn_acc.pt', map_location=map_location)\n",
    "\tmodel = model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\td = X_train.shape[2]\n",
    "\th = 128\n",
    "\tt = X_train.shape[0]\n",
    "\toutput_dim = 1\n",
    "\tdropout = 0.5\n",
    "\n",
    "\tmodel = EFLSTM(d,h,output_dim,dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 20, 325)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EFLSTM(\n",
      "  (lstm): LSTMCell(325, 128)\n",
      "  (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'input_dims': [300, 5, 20], 'batchsize': 128, 'memsize': 300, 'windowsize': 2, 'lr': 0.005, 'num_epochs': 50, 'h_dims': [64, 80, 64], 'momentum': 0.5}, {'shapes': 64, 'drop': 0.0}, {'shapes': 256, 'drop': 0.5}, {'shapes': 64, 'drop': 0.2}, {'shapes': 128, 'drop': 0.2}, {'shapes': 128, 'drop': 0.7}]\n"
     ]
    }
   ],
   "source": [
    "# d\n",
    "config = dict()\n",
    "config[\"input_dims\"] = [300,5,20]\n",
    "hl = random.choice([32,64,88,128,156,256])\n",
    "ha = random.choice([8,16,32,48,64,80])\n",
    "hv = random.choice([8,16,32,48,64,80])\n",
    "config[\"h_dims\"] = [hl,ha,hv]\n",
    "config[\"memsize\"] = random.choice([64,128,256,300,400])\n",
    "config[\"windowsize\"] = 2\n",
    "config[\"batchsize\"] = random.choice([32,64,128,256])\n",
    "config[\"num_epochs\"] = 50\n",
    "config[\"lr\"] = random.choice([0.001,0.002,0.005,0.008,0.01])\n",
    "config[\"momentum\"] = random.choice([0.1,0.3,0.5,0.6,0.8,0.9])\n",
    "NN1Config = dict()\n",
    "NN1Config[\"shapes\"] = random.choice([32,64,128,256])\n",
    "NN1Config[\"drop\"] = random.choice([0.0,0.2,0.5,0.7])\n",
    "NN2Config = dict()\n",
    "NN2Config[\"shapes\"] = random.choice([32,64,128,256])\n",
    "NN2Config[\"drop\"] = random.choice([0.0,0.2,0.5,0.7])\n",
    "gamma1Config = dict()\n",
    "gamma1Config[\"shapes\"] = random.choice([32,64,128,256])\n",
    "gamma1Config[\"drop\"] = random.choice([0.0,0.2,0.5,0.7])\n",
    "gamma2Config = dict()\n",
    "gamma2Config[\"shapes\"] = random.choice([32,64,128,256])\n",
    "gamma2Config[\"drop\"] = random.choice([0.0,0.2,0.5,0.7])\n",
    "outConfig = dict()\n",
    "outConfig[\"shapes\"] = random.choice([32,64,128,256])\n",
    "outConfig[\"drop\"] = random.choice([0.0,0.2,0.5,0.7])\n",
    "configs = [config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig]\n",
    "print configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drop': 0.5, 'shapes': 256}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN2Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MFN(config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "[config,NN1Config,NN2Config,gamma1Config,gamma2Config,outConfig] = configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\tdef train(model, batchsize, X_train, y_train, optimizer, criterion):\n",
    "\t\tepoch_loss = 0\n",
    "\t\tmodel.train()\n",
    "\t\ttotal_n = X_train.shape[1]\n",
    "\t\tnum_batches = total_n / batchsize\n",
    "\t\tfor batch in xrange(num_batches):\n",
    "\t\t\tstart = batch*batchsize\n",
    "\t\t\tend = (batch+1)*batchsize\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tbatch_X = torch.Tensor(X_train[:,start:end])\n",
    "\t\t\tbatch_y = torch.Tensor(y_train[start:end])\n",
    "\t\t\tpredictions = model.forward(batch_X).squeeze(1)\n",
    "\t\t\tloss = criterion(predictions, batch_y)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\t\t\tepoch_loss += loss.item()\n",
    "\t\treturn epoch_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1284, 20, 325)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, 0:32].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MFN(\n",
      "  (lstm_l): LSTMCell(300, 88)\n",
      "  (lstm_a): LSTMCell(5, 32)\n",
      "  (lstm_v): LSTMCell(20, 16)\n",
      "  (att1_fc1): Linear(in_features=272, out_features=64, bias=True)\n",
      "  (att1_fc2): Linear(in_features=64, out_features=272, bias=True)\n",
      "  (att1_dropout): Dropout(p=0.2, inplace=False)\n",
      "  (att2_fc1): Linear(in_features=272, out_features=256, bias=True)\n",
      "  (att2_fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (att2_dropout): Dropout(p=0.7, inplace=False)\n",
      "  (gamma1_fc1): Linear(in_features=400, out_features=256, bias=True)\n",
      "  (gamma1_fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (gamma1_dropout): Dropout(p=0.7, inplace=False)\n",
      "  (gamma2_fc1): Linear(in_features=400, out_features=256, bias=True)\n",
      "  (gamma2_fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (gamma2_dropout): Dropout(p=0.2, inplace=False)\n",
      "  (out_fc1): Linear(in_features=264, out_features=128, bias=True)\n",
      "  (out_fc2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  (out_dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\tpredictions = predict(model, X_test)\n",
    "\tprint predictions.shape\n",
    "\tprint y_test.shape\n",
    "\tmae = np.mean(np.absolute(predictions-y_test))\n",
    "\tprint \"mae: \", mae\n",
    "\tcorr = np.corrcoef(predictions,y_test)[0][1]\n",
    "\tprint \"corr: \", corr\n",
    "\tmult = round(sum(np.round(predictions)==np.round(y_test))/float(len(y_test)),5)\n",
    "\tprint \"mult_acc: \", mult\n",
    "\tf_score = round(f1_score(np.round(predictions),np.round(y_test),average='weighted'),5)\n",
    "\tprint \"mult f_score: \", f_score\n",
    "\ttrue_label = (y_test >= 0)\n",
    "\tpredicted_label = (predictions >= 0)\n",
    "\tprint \"Confusion Matrix :\"\n",
    "\tprint confusion_matrix(true_label, predicted_label)\n",
    "\tprint \"Classification Report :\"\n",
    "\tprint classification_report(true_label, predicted_label, digits=5)\n",
    "\tprint \"Accuracy \", accuracy_score(true_label, predicted_label)\n",
    "\tsys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(686,)\n",
      "(686,)\n",
      "mae:  0.9897222415474305\n",
      "corr:  0.6544623002092042\n",
      "mult_acc:  0.30029\n",
      "mult f_score:  0.33985\n",
      "Confusion Matrix :\n",
      "[[328  51]\n",
      " [104 203]]\n",
      "Classification Report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False    0.75926   0.86544   0.80888       379\n",
      "        True    0.79921   0.66124   0.72371       307\n",
      "\n",
      "   micro avg    0.77405   0.77405   0.77405       686\n",
      "   macro avg    0.77924   0.76334   0.76629       686\n",
      "weighted avg    0.77714   0.77405   0.77076       686\n",
      "\n",
      "Accuracy  0.7740524781341108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chenlin/miniconda3/envs/py2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "test(X_test, y_test, 'acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py2]",
   "language": "python",
   "name": "conda-env-py2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
